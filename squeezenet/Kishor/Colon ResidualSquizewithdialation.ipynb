{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"CKBbUQoc_8tJ"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting split-folders\n","  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n","Installing collected packages: split-folders\n","Successfully installed split-folders-0.5.1\n"]}],"source":["!pip install split-folders\n","import splitfolders\n","from google.colab import drive\n","drive.mount('/content/drive')\n","splitfolders.ratio(\"/content/drive/MyDrive/PhDProject/colon_image_sets\",\n","            output=\"splitted_data\",\n","            seed=42,\n","            ratio=(.7, .2, .1),\n","            group_prefix=None,\n","            move=False)"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":301,"status":"ok","timestamp":1702150885136,"user":{"displayName":"Kishor Ravikumar","userId":"16952462365572801429"},"user_tz":0},"id":"u3yqd15ltHov"},"outputs":[],"source":["from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Activation, GlobalAveragePooling2D, Input, Concatenate, Add\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import CategoricalCrossentropy\n","\n","def fire_module(x, squeeze_filters, expand1x1_filters, expand3x3_filters, dilation_rate=1):\n","    squeeze = Conv2D(filters=squeeze_filters, kernel_size=(1, 1), activation='relu')(x)\n","\n","    expand1x1 = Conv2D(filters=expand1x1_filters, kernel_size=(1, 1), activation='relu')(squeeze)\n","    expand3x3 = Conv2D(filters=expand3x3_filters, kernel_size=(3, 3), activation='relu', dilation_rate=dilation_rate, padding='same')(squeeze)\n","\n","    return Concatenate()([expand1x1, expand3x3])\n","\n","def create_squeezenet_dilated_residual(input_shape, num_classes):\n","    input_tensor = Input(shape=input_shape)\n","\n","    x = Conv2D(64, (3, 3), activation='relu', padding='valid')(input_tensor)\n","    x = MaxPooling2D(pool_size=(2, 2))(x)\n","\n","    # First Residual Block\n","    residual = fire_module(x, 16, 64, 64, dilation_rate=2)\n","    residual = Conv2D(64, (1, 1), activation='relu')(residual)\n","    x = fire_module(x, 16, 64, 64, dilation_rate=2)\n","    x = Conv2D(64, (1, 1), activation='relu')(x)\n","    x = Add()([x, residual])\n","\n","    x = MaxPooling2D(pool_size=(2, 2))(x)\n","\n","    # Second Residual Block\n","    residual = fire_module(x, 32, 128, 128, dilation_rate=3)\n","    residual = Conv2D(128, (1, 1), activation='relu')(residual)\n","    x = fire_module(x, 32, 128, 128, dilation_rate=3)\n","    x = Conv2D(128, (1, 1), activation='relu')(x)\n","    x = Add()([x, residual])\n","\n","    x = MaxPooling2D(pool_size=(2, 2))(x)\n","\n","    # Third Residual Block\n","    residual = fire_module(x, 48, 192, 192, dilation_rate=4)\n","    residual = Conv2D(192, (1, 1), activation='relu')(residual)\n","    x = fire_module(x, 48, 192, 192, dilation_rate=4)\n","    x = Conv2D(192, (1, 1), activation='relu')(x)\n","    x = Add()([x, residual])\n","\n","    x = GlobalAveragePooling2D()(x)\n","\n","    output = Dense(num_classes, activation='softmax')(x)\n","\n","    model = Model(inputs=input_tensor, outputs=output)\n","    return model\n","\n","# Rest of the code remains unchanged\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":436},"executionInfo":{"elapsed":2361,"status":"error","timestamp":1702150891717,"user":{"displayName":"Kishor Ravikumar","userId":"16952462365572801429"},"user_tz":0},"id":"YNW5S87YfDpX","outputId":"80eb3f87-b4bf-4c69-fb44-f62fb51aa149"},"outputs":[{"ename":"FileNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-3-53c587cdbeca\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 24\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 24\u001b[0;31m train_generator = train_datagen.flow_from_directory(\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;34m\"/content/splitted_data/train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1646\u001b[0m                 \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m         \"\"\"\n\u001b[0;32m-\u003e 1648\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1649\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 563\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/splitted_data/train'"]}],"source":["import matplotlib.pyplot as plt\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import CategoricalCrossentropy\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","input_shape=(244,244,3)\n","# Assuming 'create_squeezenet_dilated_residual' function returns the model architecture\n","model = create_squeezenet_dilated_residual((input_shape), num_classes=2)  # Ensure num_classes is set to 2\n","\n","# Define the optimizer and loss function\n","optimizer = Adam()\n","loss_function = CategoricalCrossentropy()\n","\n","# Compile the model\n","model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n","\n","# Data Preprocessing and Data Augmentation for training data\n","train_datagen = ImageDataGenerator(\n","    rescale=1.0 / 255.0,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True\n",")\n","\n","train_generator = train_datagen.flow_from_directory(\n","    \"/content/splitted_data/train\",\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n","\n","# Data Preprocessing for validation data\n","val_datagen = ImageDataGenerator(\n","    rescale=1.0 / 255.0\n",")\n","\n","val_generator = val_datagen.flow_from_directory(\n","    \"/content/splitted_data/val\",\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n","\n","# Training the model with validation data\n","epochs = 50\n","steps_per_epoch = len(train_generator)\n","validation_steps = len(val_generator)\n","\n","try:\n","    history = model.fit(\n","        train_generator,\n","        epochs=epochs,\n","        steps_per_epoch=steps_per_epoch,\n","        validation_data=val_generator,\n","        validation_steps=validation_steps\n","    )\n","except Exception as e:\n","    print(\"An error occurred during training:\", str(e))\n","\n","# Plot the training and validation losses\n","plt.figure(figsize=(8, 6))\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training and Validation Loss Over Time')\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U-LABQ6RuA3T"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.profiler import ProfilerSession\n","from tensorflow.python.framework.ops import get_name_scope\n","\n","# Create and compile your TensorFlow model\n","#model = tf.keras.applications.MobileNetV2(weights='imagenet', input_shape=(224, 224, 3))\n","#model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Create a sample input tensor for profiling\n","input_tensor = tf.random.uniform((1, 224, 224, 3))\n","\n","# Run a session with profiler\n","with ProfilerSession() as prof:\n","    # Run a forward pass with the model\n","    model(input_tensor)\n","\n","# Extract statistics from the profiler\n","stats = prof.profile_ops\n","total_flops = sum([op.stats.total_float_ops for op in stats.values()])\n","\n","print(f\"Total FLOPS: {total_flops}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JqbH3CorD0Kb"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","# Plot the training and validation losses\n","plt.plot(history.history['loss'],label = 'Training loss')\n","plt.plot(history.history['val_loss'], label = 'Validation loss')\n","#plt.title('loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bql6S2Q7EG35"},"outputs":[],"source":["# Both Validation and Training accuracy is shown here\n","\n","plt.plot(history.history['accuracy'], label='Training accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation accuracy')\n","#plt.title('Accuracy')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZFPIHzzPEIJF"},"outputs":[],"source":["# CHECKING THE CONFUSION MATRIX\n","\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import f1_score\n","Y_pred = model.predict(test_set)\n","y_pred = np.argmax(Y_pred ,axis =1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1fWXm5rBEPJi"},"outputs":[],"source":["print('Classification Report')\n","target_names = ['aca','n']\n","print(classification_report(test_set.classes, y_pred, target_names=target_names))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nTj3wfJaEUY-"},"outputs":[],"source":["loss, acc = model.evaluate_generator(test_set, len(test_set))\n","\n","print (\"\\n\\n================================\\n\\n\")\n","print (\"Loss: {}\".format(loss))\n","print (\"Accuracy: {0:.2f} %\".format(acc * 100))\n","print (\"\\n\\n================================\\n\\n\")\n","\n","test_set.reset()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9FcdnhFcEXfb"},"outputs":[],"source":["result = model.evaluate(test_set,batch_size=128)\n","print(\"test_loss, test accuracy\",result)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aSEwaMUWEb0E"},"outputs":[],"source":["preds = model.predict(test_set,verbose=1)\n","predictions = preds.copy()\n","predictions[predictions \u003c= 0.5] = 0\n","predictions[predictions \u003e 0.5] = 1"]}],"metadata":{"accelerator":"TPU","colab":{"authorship_tag":"ABX9TyNKulg04CVtHqYRCBYlwrNf","machine_shape":"hm","name":"","provenance":[{"file_id":"1CC-d9MPQjyZf2bvBmdttMJCw69sjFEfu","timestamp":1691007040158}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}