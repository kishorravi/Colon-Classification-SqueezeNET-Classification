{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":526065,"status":"ok","timestamp":1691228919118,"user":{"displayName":"Kishor Ravikumar","userId":"16952462365572801429"},"user_tz":-60},"id":"CKBbUQoc_8tJ","outputId":"92cda775-f9a3-4b8d-dc9f-e97e383a82f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting split-folders\n","  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n","Installing collected packages: split-folders\n","Successfully installed split-folders-0.5.1\n","Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["Copying files: 10000 files [08:06, 20.53 files/s]\n"]}],"source":["!pip install split-folders\n","import splitfolders\n","from google.colab import drive\n","drive.mount('/content/drive')\n","splitfolders.ratio(\"/content/drive/MyDrive/PhDProject/colon_image_sets\",\n","            output=\"splitted_data\",\n","            seed=42,\n","            ratio=(.7, .2, .1),\n","            group_prefix=None,\n","            move=False)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"7ZzPXlDrnXIj","executionInfo":{"status":"ok","timestamp":1691228923380,"user_tz":-60,"elapsed":4287,"user":{"displayName":"Kishor Ravikumar","userId":"16952462365572801429"}}},"outputs":[],"source":["import tensorflow as tf\n","\n","def fire_module(x, squeeze_channels, expand1x1_channels, expand3x3_channels, dilation=1):\n","    x = tf.keras.layers.Conv2D(squeeze_channels, kernel_size=1, activation='relu')(x)\n","    x = tf.keras.layers.BatchNormalization()(x)  # Add Batch Normalization after the first Conv2D\n","    x = tf.keras.layers.Conv2D(expand1x1_channels, kernel_size=1, activation='relu')(x)\n","    x = tf.keras.layers.BatchNormalization()(x)  # Add Batch Normalization after the second Conv2D\n","    x = tf.keras.layers.Conv2D(expand3x3_channels, kernel_size=3, padding='same', dilation_rate=dilation, activation='relu')(x)\n","    x = tf.keras.layers.BatchNormalization()(x)  # Add Batch Normalization after the third Conv2D\n","    return x\n","\n","def SqueezeNet1_2_dilation(input_shape, num_classes):\n","    input_tensor = tf.keras.layers.Input(shape=input_shape)\n","\n","    x = tf.keras.layers.Conv2D(96, kernel_size=7, strides=2, padding='same', activation='relu')(input_tensor)\n","    x = tf.keras.layers.MaxPooling2D(pool_size=3, strides=2)(x)\n","\n","    x = fire_module(x, 16, 64, 64, dilation=1)\n","    x = fire_module(x, 16, 64, 64, dilation=1)\n","    x = fire_module(x, 32, 128, 128, dilation=1)\n","\n","    x = tf.keras.layers.MaxPooling2D(pool_size=3, strides=2)(x)\n","\n","    x = fire_module(x, 32, 128, 128, dilation=2)\n","    x = fire_module(x, 48, 192, 192, dilation=2)\n","    x = fire_module(x, 48, 192, 192, dilation=2)\n","    x = fire_module(x, 64, 256, 256, dilation=2)\n","\n","    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n","    output_tensor = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n","\n","    model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n","\n","    return model\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"YNW5S87YfDpX","outputId":"3612e1fa-d20e-4850-b922-c690a4c99c2f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 7000 images belonging to 2 classes.\n","Found 2000 images belonging to 2 classes.\n","Epoch 1/50\n","219/219 [==============================] - 1864s 8s/step - loss: 0.1942 - accuracy: 0.9250 - val_loss: 3.5381 - val_accuracy: 0.5000\n","Epoch 2/50\n","219/219 [==============================] - 1852s 8s/step - loss: 0.0667 - accuracy: 0.9739 - val_loss: 8.1837 - val_accuracy: 0.5095\n","Epoch 3/50\n","219/219 [==============================] - 1805s 8s/step - loss: 0.0532 - accuracy: 0.9813 - val_loss: 2.4836 - val_accuracy: 0.4770\n","Epoch 4/50\n","219/219 [==============================] - 1812s 8s/step - loss: 0.0396 - accuracy: 0.9861 - val_loss: 4.3088 - val_accuracy: 0.6290\n","Epoch 5/50\n","219/219 [==============================] - 1806s 8s/step - loss: 0.0359 - accuracy: 0.9869 - val_loss: 11.0039 - val_accuracy: 0.5000\n","Epoch 6/50\n","219/219 [==============================] - 1796s 8s/step - loss: 0.0222 - accuracy: 0.9926 - val_loss: 5.8010 - val_accuracy: 0.5190\n","Epoch 7/50\n","219/219 [==============================] - 1795s 8s/step - loss: 0.0287 - accuracy: 0.9900 - val_loss: 1.5587 - val_accuracy: 0.6275\n","Epoch 8/50\n","219/219 [==============================] - 1806s 8s/step - loss: 0.0268 - accuracy: 0.9913 - val_loss: 14.9205 - val_accuracy: 0.5000\n","Epoch 9/50\n","219/219 [==============================] - 1819s 8s/step - loss: 0.0352 - accuracy: 0.9874 - val_loss: 0.8607 - val_accuracy: 0.6155\n","Epoch 10/50\n","219/219 [==============================] - 1786s 8s/step - loss: 0.0187 - accuracy: 0.9940 - val_loss: 0.6997 - val_accuracy: 0.7345\n","Epoch 11/50\n","219/219 [==============================] - 1785s 8s/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.2369 - val_accuracy: 0.9070\n","Epoch 12/50\n","219/219 [==============================] - 1814s 8s/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 4.4722 - val_accuracy: 0.5000\n","Epoch 13/50\n","219/219 [==============================] - 1797s 8s/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 1.0186 - val_accuracy: 0.5245\n","Epoch 14/50\n","219/219 [==============================] - 1770s 8s/step - loss: 0.0158 - accuracy: 0.9957 - val_loss: 0.6335 - val_accuracy: 0.7795\n","Epoch 15/50\n","219/219 [==============================] - 1774s 8s/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 1.2657 - val_accuracy: 0.6715\n","Epoch 16/50\n","219/219 [==============================] - 1800s 8s/step - loss: 0.0121 - accuracy: 0.9953 - val_loss: 2.5770 - val_accuracy: 0.5000\n","Epoch 17/50\n","219/219 [==============================] - 1787s 8s/step - loss: 0.0268 - accuracy: 0.9921 - val_loss: 0.5588 - val_accuracy: 0.7140\n","Epoch 18/50\n","189/219 [========================>.....] - ETA: 3:46 - loss: 0.0129 - accuracy: 0.9950"]}],"source":["import matplotlib.pyplot as plt\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import CategoricalCrossentropy\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Assuming 'create_squeezenet_dilated_residual' function returns the model architecture\n","model = SqueezeNet1_2_dilation(input_shape=(224, 224, 3), num_classes=2)\n","# Define the optimizer and loss function\n","optimizer = Adam()\n","loss_function = CategoricalCrossentropy()\n","\n","# Compile the model\n","model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n","\n","# Data Preprocessing and Data Augmentation for training data\n","train_datagen = ImageDataGenerator(\n","    rescale=1.0 / 255.0,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True\n",")\n","\n","train_generator = train_datagen.flow_from_directory(\n","    \"/content/splitted_data/train\",\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n","\n","# Data Preprocessing for validation data\n","val_datagen = ImageDataGenerator(\n","    rescale=1.0 / 255.0\n",")\n","\n","val_generator = val_datagen.flow_from_directory(\n","    \"/content/splitted_data/val\",\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n","\n","# Training the model with validation data\n","epochs = 50\n","steps_per_epoch = len(train_generator)\n","validation_steps = len(val_generator)\n","\n","try:\n","    history = model.fit(\n","        train_generator,\n","        epochs=epochs,\n","        steps_per_epoch=steps_per_epoch,\n","        validation_data=val_generator,\n","        validation_steps=validation_steps\n","    )\n","except Exception as e:\n","    print(\"An error occurred during training:\", str(e))\n","\n","# Plot the training and validation losses\n","plt.figure(figsize=(8, 6))\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training and Validation Loss Over Time')\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"JqbH3CorD0Kb","colab":{"base_uri":"https://localhost:8080/","height":242},"executionInfo":{"status":"error","timestamp":1691228386634,"user_tz":-60,"elapsed":235,"user":{"displayName":"Kishor Ravikumar","userId":"16952462365572801429"}},"outputId":"9f40c492-4c21-4e9e-ac91-de09c4bf7b05"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-a1d0e957c757>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Plot the training and validation losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Training loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Validation loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#plt.title('loss')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"]}],"source":["import matplotlib.pyplot as plt\n","# Plot the training and validation losses\n","plt.plot(history.history['loss'],label = 'Training loss')\n","plt.plot(history.history['val_loss'], label = 'Validation loss')\n","#plt.title('loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bql6S2Q7EG35"},"outputs":[],"source":["# Both Validation and Training accuracy is shown here\n","\n","plt.plot(history.history['accuracy'], label='Training accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation accuracy')\n","#plt.title('Accuracy')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b_ttEO9lNnhC"},"outputs":[],"source":["test_set = val_datagen.flow_from_directory(\n","    \"/content/splitted_data/test\",\n","    target_size=(224, 224),\n","    batch_size=8,\n","    class_mode='categorical'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZFPIHzzPEIJF"},"outputs":[],"source":["# CHECKING THE CONFUSION MATRIX\n","\n","import numpy as np # linear algebra\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import f1_score\n","Y_pred = model.predict(test_set)\n","y_pred = np.argmax(Y_pred ,axis =1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1fWXm5rBEPJi"},"outputs":[],"source":["print('Classification Report')\n","target_names = ['aca','n']\n","print(classification_report(test_set.classes, y_pred, target_names=target_names))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nTj3wfJaEUY-"},"outputs":[],"source":["loss, acc = model.evaluate_generator(test_set, len(test_set))\n","\n","print (\"\\n\\n================================\\n\\n\")\n","print (\"Loss: {}\".format(loss))\n","print (\"Accuracy: {0:.2f} %\".format(acc * 100))\n","print (\"\\n\\n================================\\n\\n\")\n","\n","test_set.reset()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9FcdnhFcEXfb"},"outputs":[],"source":["result = model.evaluate(test_set,batch_size=128)\n","print(\"test_loss, test accuracy\",result)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aSEwaMUWEb0E"},"outputs":[],"source":["preds = model.predict(test_set,verbose=1)\n","predictions = preds.copy()\n","predictions[predictions <= 0.5] = 0\n","predictions[predictions > 0.5] = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8lM-goqh1hxK"},"outputs":[],"source":["\n","#Confusion Matrix and Classification Report\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","\n","#Y_pred = model.predict_generator(validation_generator, nb_validation_samples //\n","#batch_size+1)\n","y_pred = np.argmax(preds, axis=1)\n","\n","print('Confusion Matrix')\n","print(confusion_matrix(test_set.classes, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"47a9XKUw1qty"},"outputs":[],"source":["print('Classification Report')\n","target_names = [ 'Colon Benign','Colon Adenocarcinoma']\n","print(classification_report(test_set.classes, y_pred, target_names=target_names))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eeFqxE1E1wIS"},"outputs":[],"source":["from sklearn.metrics import precision_score, recall_score\n","from sklearn.metrics import f1_score\n","\n","precision_score(test_set.classes, y_pred) , recall_score(test_set.classes, y_pred) ,  f1_score(test_set.classes, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OtOPHUkS1x6d"},"outputs":[],"source":["import sklearn.metrics as metrics\n","fpr, tpr, threshold = metrics.roc_curve(test_set.classes, y_pred)\n","roc_auc = metrics.auc(fpr, tpr)\n","import matplotlib.pyplot as plt\n","#plt.title('Receiver Operating Characteristic')\n","plt.plot(fpr, tpr, 'b', label = 'AUC = %0.3f' % roc_auc)\n","plt.legend(loc = 'lower right')\n","plt.plot([0, 1], [0, 1],'k--')\n","# plt.xlim([0, 1])\n","# plt.ylim([0, 1])\n","plt.ylabel('True Positive Rate')\n","plt.xlabel('False Positive Rate')\n","#plt.title('ROC curve')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9HAGrZ8W15jg"},"outputs":[],"source":["import pandas as pd\n","from sklearn.metrics import classification_report,confusion_matrix\n","cm = pd.DataFrame(data=confusion_matrix( y_true= test_set.classes, y_pred= y_pred, labels=[0, 1]), index=[\"Actual Normal\", \"Actul Adenocarcinoma\"],columns=[\"Predicted Benign\", \"Predicted Adenocarcinoma\"])\n","import seaborn as sns\n","sns.heatmap(cm,annot=True,fmt=\"d\",cmap=\"BuPu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FyglE1DXCAEw"},"outputs":[],"source":["pip install tflops"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9xYZzklICBsW"},"outputs":[],"source":["import tensorflxow as tf\n","from tflops import get_flops\n","\n","# Assuming you have already created and compiled your model\n","model = your_model_function()\n","\n","# Print the FLOPs\n","flops = get_flops(model)\n","print(\"FLOPs:\", flops)"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[{"file_id":"1SxvHVm3fHrMAEjlTtqdFZ5uG5lhMinpo","timestamp":1691048896351},{"file_id":"17qknRZaHrV6bbMmSZ-yz3CgMyoJ07-aL","timestamp":1691048099151},{"file_id":"1GimgnOZx2FVdhhJbMPPb8UPssUOM0X0-","timestamp":1691046622795},{"file_id":"1b9iaKU4HSvJW5nsWI7ABQKf6I0QV2k8D","timestamp":1691040549460},{"file_id":"1CC-d9MPQjyZf2bvBmdttMJCw69sjFEfu","timestamp":1691007040158}],"authorship_tag":"ABX9TyNGcPbg3KCO1+ZINt3Ans1j"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}